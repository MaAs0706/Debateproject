Directory structure:
â””â”€â”€ stellarcompiler-debateproject/
    â”œâ”€â”€ auth.html
    â”œâ”€â”€ dashboard.html
    â”œâ”€â”€ hero.html
    â”œâ”€â”€ main.py
    â”œâ”€â”€ response.html
    â””â”€â”€ styles.css
# ðŸš€ FastAPI AI Streaming Backend with Ollama Integration

This project is a FastAPI backend that integrates with **Ollama** to stream AI-generated responses using `httpx` and `StreamingResponse`. It supports SSE (Server-Sent Events) for real-time token streaming, and is deployable on [Render.com](https://render.com) via GitHub.

---

## ðŸ§  Features

- âœ… FastAPI + HTTPX for asynchronous API
- âœ… Supports real-time token streaming from Ollama
- âœ… JSON parsing with error handling
- âœ… Customizable HTTP timeout settings
- âœ… CORS enabled for frontend integration

---

## ðŸ“¦ Technologies Used

- [FastAPI](https://fastapi.tiangolo.com/)
- [Uvicorn](https://www.uvicorn.org/)
- [HTTPX](https://www.python-httpx.org/)
- [Ollama](https://ollama.com/) (Locally running AI model)
- Python 3.10+
- Javascript
- Basic CSS
- HTML 5
